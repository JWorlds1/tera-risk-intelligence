{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF Analyse und Information Retrieval\n",
    "\n",
    "In diesem Notebook implementieren wir ein TF-IDF basiertes IR-System und analysieren dessen Funktionsweise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Daten laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../data')\n",
    "csv_path = data_dir / 'tagesschau_2023_prepared.csv'\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"Geladene Artikel: {len(df)}\")\n",
    "\n",
    "# Identifiziere Text-Spalte\n",
    "text_column = None\n",
    "for col in ['text', 'content', 'article', 'body']:\n",
    "    if col in df.columns:\n",
    "        text_column = col\n",
    "        break\n",
    "\n",
    "if text_column is None:\n",
    "    text_column = df.columns[0]\n",
    "\n",
    "documents = df[text_column].dropna().tolist()\n",
    "print(f\"Verwendete Text-Spalte: {text_column}\")\n",
    "print(f\"Anzahl Dokumente: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TF-IDF Vectorizer initialisieren\n",
    "\n",
    "### Verständnisfragen:\n",
    "1. Was bedeutet `fit_transform`?\n",
    "2. Wie wird TF-IDF in scikit-learn berechnet?\n",
    "3. Welche Normalisierungsoptionen gibt es?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisiere TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95,\n",
    "    norm='l2',\n",
    "    use_idf=True,\n",
    "    smooth_idf=True,\n",
    "    sublinear_tf=False,\n",
    "    lowercase=True,\n",
    "    stop_words=None\n",
    ")\n",
    "\n",
    "print(\"TF-IDF Vectorizer Parameter:\")\n",
    "print(f\"  max_features: {vectorizer.max_features}\")\n",
    "print(f\"  ngram_range: {vectorizer.ngram_range}\")\n",
    "print(f\"  min_df: {vectorizer.min_df}\")\n",
    "print(f\"  max_df: {vectorizer.max_df}\")\n",
    "print(f\"  norm: {vectorizer.norm}\")\n",
    "print(f\"  use_idf: {vectorizer.use_idf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TF-IDF Matrix berechnen\n",
    "\n",
    "### Was passiert bei `fit_transform`?\n",
    "- **fit**: Lernt das Vokabular aus allen Dokumenten und berechnet IDF-Werte\n",
    "- **transform**: Wendet die gelernten Transformationen an und erstellt TF-IDF Vektoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne TF-IDF Matrix\n",
    "print(\"Berechne TF-IDF Matrix...\")\n",
    "tfidf_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "print(f\"\\nTF-IDF Matrix Shape: {tfidf_matrix.shape}\")\n",
    "print(f\"  Anzahl Dokumente: {tfidf_matrix.shape[0]}\")\n",
    "print(f\"  Anzahl Features: {tfidf_matrix.shape[1]}\")\n",
    "print(f\"  Matrix-Dichte: {tfidf_matrix.nnz / (tfidf_matrix.shape[0] * tfidf_matrix.shape[1]):.4f}\")\n",
    "\n",
    "# Zeige Feature-Namen\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"\\nErste 20 Features: {feature_names[:20].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. IDF-Werte analysieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zeige IDF-Werte\n",
    "idf_values = vectorizer.idf_\n",
    "\n",
    "print(f\"IDF-Werte:\")\n",
    "print(f\"  Min: {idf_values.min():.4f}\")\n",
    "print(f\"  Max: {idf_values.max():.4f}\")\n",
    "print(f\"  Mean: {idf_values.mean():.4f}\")\n",
    "print(f\"  Median: {np.median(idf_values):.4f}\")\n",
    "\n",
    "# Top Features nach IDF (seltene Wörter)\n",
    "top_idf_indices = np.argsort(idf_values)[-20:][::-1]\n",
    "print(f\"\\nTop 20 Features nach IDF (seltene Wörter):\")\n",
    "for idx in top_idf_indices:\n",
    "    print(f\"  {feature_names[idx]}: {idf_values[idx]:.4f}\")\n",
    "\n",
    "# Bottom Features nach IDF (häufige Wörter)\n",
    "bottom_idf_indices = np.argsort(idf_values)[:20]\n",
    "print(f\"\\nBottom 20 Features nach IDF (häufige Wörter):\")\n",
    "for idx in bottom_idf_indices:\n",
    "    print(f\"  {feature_names[idx]}: {idf_values[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualisierung der IDF-Verteilung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(idf_values, bins=50, edgecolor='black')\n",
    "plt.xlabel('IDF-Wert')\n",
    "plt.ylabel('Anzahl Features')\n",
    "plt.title('Verteilung der IDF-Werte')\n",
    "plt.axvline(idf_values.mean(), color='r', linestyle='--', label=f'Mean: {idf_values.mean():.4f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(idf_values)\n",
    "plt.ylabel('IDF-Wert')\n",
    "plt.title('Boxplot der IDF-Werte')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Suchfunktion implementieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, top_k=10):\n",
    "    \"\"\"\n",
    "    Sucht nach ähnlichen Dokumenten\n",
    "    \"\"\"\n",
    "    # Transformiere Query zu TF-IDF Vektor\n",
    "    query_vector = vectorizer.transform([query])\n",
    "    \n",
    "    # Berechne Kosinus-Ähnlichkeit\n",
    "    similarities = cosine_similarity(query_vector, tfidf_matrix)[0]\n",
    "    \n",
    "    # Sortiere nach Ähnlichkeit\n",
    "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
    "    \n",
    "    results = [(idx, similarities[idx]) for idx in top_indices if similarities[idx] > 0]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test-Suchen durchführen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"Klimawandel\",\n",
    "    \"Ukraine Krieg\",\n",
    "    \"Bundesregierung\",\n",
    "    \"Wirtschaft\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Suche: '{query}'\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    results = search(query, top_k=5)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"Keine Ergebnisse gefunden.\")\n",
    "        continue\n",
    "    \n",
    "    for i, (idx, score) in enumerate(results, 1):\n",
    "        print(f\"\\n--- Ergebnis {i} (Score: {score:.4f}) ---\")\n",
    "        doc = documents[idx]\n",
    "        preview = doc[:300] + \"...\" if len(doc) > 300 else doc\n",
    "        print(f\"Index: {idx}\")\n",
    "        print(f\"Text: {preview}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyse und Verbesserungsvorschläge\n",
    "\n",
    "### Diskussionspunkte:\n",
    "1. Wie finden Sie das IR-System?\n",
    "2. Was wären nächste Schritte zur Verbesserung?\n",
    "3. Welche Vorverarbeitungsschritte könnten helfen?\n",
    "4. Welche Informationen sind noch im Datensatz enthalten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysiere Metadaten im Datensatz\n",
    "print(\"Verfügbare Spalten im Datensatz:\")\n",
    "for col in df.columns:\n",
    "    print(f\"  - {col}: {df[col].dtype}\")\n",
    "    if df[col].dtype == 'object':\n",
    "        unique_count = df[col].nunique()\n",
    "        print(f\"    Unique Werte: {unique_count}\")\n",
    "        if unique_count < 20:\n",
    "            print(f\"    Werte: {df[col].unique()[:10].tolist()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}