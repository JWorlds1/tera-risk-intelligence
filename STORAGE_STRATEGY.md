# ğŸ“¦ Storage-Strategie fÃ¼r Geospatial Intelligence Projekt

## ğŸ¯ Ziel

**900 GB verfÃ¼gbarer Speicher** fÃ¼r gecrawlte Daten optimal nutzen mit Fokus auf **maximale Arbeitsspeicher-Ressourcen**.

## ğŸ’¾ OpenStack Storage-Optionen

### 1. Object Storage (Swift) - **EMPFOHLEN** âœ…

**Vorteile:**
- âœ… Skalierbar bis zu mehreren TB
- âœ… Geeignet fÃ¼r viele kleine Dateien (gecrawlte Daten)
- âœ… Automatische Replikation und Backup
- âœ… GÃ¼nstig fÃ¼r Archivierung
- âœ… REST API fÃ¼r einfache Integration
- âœ… Keine Limits auf DateigrÃ¶ÃŸe

**Verwendung:**
- Gecrawlte HTML/JSON/CSV Dateien
- Bilder und Medien
- Archivierte Daten
- Backup der SQLite-Datenbank

### 2. Block Storage (Cinder) - Alternative

**Vorteile:**
- âœ… HÃ¶here Performance
- âœ… Geeignet fÃ¼r Datenbanken
- âœ… Direkter Dateisystem-Zugriff

**Nachteile:**
- âŒ Weniger flexibel
- âŒ Teurer
- âŒ Feste GrÃ¶ÃŸe

**Verwendung:**
- PostgreSQL-Datenbank (falls Migration)
- Performance-kritische Daten

## ğŸ“Š Ressourcenverteilung (900 GB)

### Empfohlene Aufteilung:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenStack Object Storage (Swift)               â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                  â”‚
â”‚  ğŸ“ Container: crawled-data                     â”‚
â”‚     â””â”€ 600 GB (67%) - Gecrawlte Rohdaten       â”‚
â”‚        â”œâ”€ HTML/JSON Dateien                     â”‚
â”‚        â”œâ”€ Bilder                                â”‚
â”‚        â””â”€ Medien                                â”‚
â”‚                                                  â”‚
â”‚  ğŸ“ Container: processed-data                   â”‚
â”‚     â””â”€ 200 GB (22%) - Verarbeitete Daten        â”‚
â”‚        â”œâ”€ Parquet Dateien                       â”‚
â”‚        â”œâ”€ CSV Exporte                           â”‚
â”‚        â””â”€ Analysen                              â”‚
â”‚                                                  â”‚
â”‚  ğŸ“ Container: database-backups                 â”‚
â”‚     â””â”€ 50 GB (6%) - Datenbank-Backups          â”‚
â”‚        â”œâ”€ SQLite Snapshots                      â”‚
â”‚        â””â”€ PostgreSQL Dumps                      â”‚
â”‚                                                  â”‚
â”‚  ğŸ“ Container: embeddings                       â”‚
â”‚     â””â”€ 50 GB (5%) - Vektor-Embeddings          â”‚
â”‚        â”œâ”€ Text-Embeddings                       â”‚
â”‚        â””â”€ Bild-Embeddings                       â”‚
â”‚                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Gesamt: 900 GB
```

## ğŸ—ï¸ Architektur-Integration

### Aktuelle Datenstruktur:

```
data/
â”œâ”€â”€ climate_conflict.db          # SQLite Datenbank
â”œâ”€â”€ json/                         # JSON Exporte
â”œâ”€â”€ csv/                          # CSV Exporte
â”œâ”€â”€ parquet/                      # Parquet Dateien
â””â”€â”€ analytics/                    # Analysen
```

### Neue Struktur mit OpenStack:

```
Lokal (Development):
data/
â”œâ”€â”€ climate_conflict.db          # SQLite (lokale Kopie)
â””â”€â”€ cache/                        # Lokaler Cache

OpenStack Swift:
crawled-data/
â”œâ”€â”€ raw/                          # Rohdaten
â”‚   â”œâ”€â”€ nasa/                     # NASA Daten
â”‚   â”œâ”€â”€ un_press/                 # UN Press Daten
â”‚   â””â”€â”€ worldbank/                # World Bank Daten
â”œâ”€â”€ processed/                    # Verarbeitete Daten
â””â”€â”€ metadata/                     # Metadaten

database-backups/
â”œâ”€â”€ daily/                        # TÃ¤gliche Backups
â””â”€â”€ weekly/                       # WÃ¶chentliche Backups
```

## ğŸ”„ Workflow-Integration

### 1. Crawling-Pipeline â†’ OpenStack Storage

```python
# Nach erfolgreichem Crawling:
1. Speichere lokal (fÃ¼r schnellen Zugriff)
2. Upload zu OpenStack Swift (fÃ¼r Archivierung)
3. Update Metadaten in Datenbank
```

### 2. Automatischer Upload

```python
# Nach jedem Crawl-Job:
- Upload neue Dateien zu Swift
- Komprimiere groÃŸe Dateien
- Erstelle Metadaten-Index
```

### 3. Datenbank-Backup

```python
# TÃ¤glich:
- SQLite â†’ Swift Backup
- PostgreSQL Dump â†’ Swift (falls Migration)
```

## ğŸ’» Implementierung

### Storage Manager Integration

```python
from backend.openstack.storage_manager import OpenStackStorageManager

# Initialisierung
storage = OpenStackStorageManager()

# Nach Crawling
storage.upload_directory(
    local_dir="data/json",
    container_name="crawled-data",
    prefix="raw/nasa"
)

# Backup
storage.upload_file(
    local_path="data/climate_conflict.db",
    container_name="database-backups",
    object_name=f"daily/{date}.db"
)
```

## ğŸ“ˆ Performance-Optimierung

### FÃ¼r maximale Arbeitsspeicher-Nutzung:

1. **Chunked Upload** fÃ¼r groÃŸe Dateien
   - 100 MB Chunks
   - Parallele Uploads

2. **Kompression**
   - Gzip fÃ¼r Text-Dateien
   - Parquet fÃ¼r strukturierte Daten

3. **Caching-Strategie**
   - Lokaler Cache fÃ¼r hÃ¤ufig genutzte Daten
   - OpenStack fÃ¼r Archivierung

4. **Batch-Processing**
   - Upload in Batches
   - Retry-Logic

## ğŸ¯ NÃ¤chste Schritte

1. âœ… **Storage-Optionen prÃ¼fen**
   ```bash
   python3 backend/openstack/check_storage.py
   ```

2. âœ… **Container erstellen**
   ```bash
   python3 backend/openstack/storage_manager.py --create-container crawled-data
   python3 backend/openstack/storage_manager.py --create-container processed-data
   python3 backend/openstack/storage_manager.py --create-container database-backups
   ```

3. âœ… **Integration in Crawling-Pipeline**
   - Storage Manager in Pipeline einbinden
   - Automatischer Upload nach Crawling

4. âœ… **Monitoring**
   - Storage-Usage Tracking
   - Automatische Alerts bei Quota

## ğŸ” Sicherheit & Backup

- âœ… Automatische Replikation (Swift)
- âœ… Versionierung fÃ¼r wichtige Daten
- âœ… TÃ¤gliche Backups der Datenbank
- âœ… VerschlÃ¼sselung fÃ¼r sensible Daten

## ğŸ’° Kosten-Optimierung

- âœ… Kompression reduziert Speicher
- âœ… Lifecycle-Policies (alte Daten â†’ Archive)
- âœ… Intelligente Retention-Policies

