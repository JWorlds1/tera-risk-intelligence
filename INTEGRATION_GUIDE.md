# ğŸ”— System-Integration Guide

## Ãœbersicht

Dieses Dokument beschreibt, wie alle Komponenten des Climate Conflict Intelligence Systems zusammenarbeiten.

## ğŸ—ï¸ Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Master Orchestrator                         â”‚
â”‚         (Koordiniert alle Agenten)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚          â”‚          â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚Scraperâ”‚  â”‚Enrichâ”‚  â”‚Predict â”‚
â”‚Agent  â”‚  â”‚Agent â”‚  â”‚Agent   â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    â”‚         â”‚          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
         â”‚Database â”‚
         â”‚Manager  â”‚
         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
              â”‚
         â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
         â”‚ Frontendâ”‚
         â”‚  (Web)  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Komponenten

### 1. Master Orchestrator (`master_orchestrator.py`)

**Zweck**: Koordiniert alle Agenten und ermÃ¶glicht Datenaustausch

**Features**:
- Message Bus fÃ¼r Agent-Kommunikation
- Pipeline-Koordination (Scraping â†’ Enrichment â†’ Geocoding â†’ Prediction)
- Regionale Fokus-Regionen (Deutschland, Europa)
- Status-Tracking fÃ¼r alle Komponenten

**Verwendung**:
```python
from master_orchestrator import MasterOrchestrator
from config import Config

config = Config()
orchestrator = MasterOrchestrator(config)
await orchestrator.initialize()

# FÃ¼hre komplette Pipeline aus
results = await orchestrator.run_full_pipeline(
    enrich=True,
    predict=True,
    geocode=True,
    focus_regions=['Germany', 'Europe']
)
```

### 2. Scraping Orchestrator (`orchestrator.py`)

**Zweck**: Extrahiert Daten von Webseiten

**Komponenten**:
- Compliance Agent (robots.txt, Rate Limiting)
- Multi-Agent Fetcher (HTTP + Playwright Fallback)
- Extractor Factory (NASA, UN, World Bank)
- Validation Agent
- Storage Agent

**Datenquellen**:
- NASA Earth Observatory
- UN Press
- World Bank News

### 3. Enrichment Agent (`ipcc_enrichment_agent.py`)

**Zweck**: Reichert Daten mit zusÃ¤tzlichen Informationen an

**Features**:
- IPCC-basierte Datenanreicherung
- Satelliten-Daten
- Echtzeit-Daten
- Firecrawl Integration

**Verwendung**:
```python
from ipcc_enrichment_agent import DynamicEnrichmentOrchestrator

enricher = DynamicEnrichmentOrchestrator(
    firecrawl_api_key="...",
    openai_api_key="..."
)

enrichment = enricher.enrich_record_comprehensive(
    record,
    use_ipcc=True,
    use_satellite=True,
    use_real_time=True
)
```

### 4. Database Manager (`database.py`)

**Zweck**: Zentrale Datenbank-Verwaltung

**Tabellen**:
- `records` - Haupttabelle fÃ¼r alle Records
- `enriched_data` - Angereicherte Daten
- `regional_enrichment` - Regionale Aggregationen
- `regional_predictions` - Regionale Vorhersagen
- `geo_locations` - Geografische Daten
- `nasa_records`, `un_press_records`, `worldbank_records` - Source-spezifische Daten

**Verwendung**:
```python
from database import DatabaseManager

db = DatabaseManager()

# Records einfÃ¼gen
record_id, is_new = db.insert_record(record)

# Records abrufen
records = db.get_records(limit=100, source_name='NASA')

# Statistiken
stats = db.get_statistics()
```

### 5. Frontend (`web_app.py`)

**Zweck**: Web-Interface fÃ¼r Datenvisualisierung

**Endpoints**:
- `/` - Hauptdashboard
- `/api/stats` - Statistiken
- `/api/records` - Records mit Risiko-Scores
- `/api/regional-data` - Regionale Daten (Deutschland/Europa)
- `/api/regional-records` - Records fÃ¼r spezifische Region
- `/api/map-data` - Daten fÃ¼r Karte
- `/api/predictions` - Vorhersagen
- `/api/enrichment` - Enrichment-Statistiken

**Tabs**:
1. **Karte** - Interaktive Weltkarte mit Risiko-Markern
2. **Records** - Liste aller Records mit Risiko-Scores
3. **Regionen** - Regionale Ãœbersicht (Deutschland/Europa)
4. **Enrichment** - Angereicherte Daten
5. **Predictions** - Vorhersagen fÃ¼r gefÃ¤hrdete Regionen
6. **Datenquellen** - Informationen zu Datenquellen

## ğŸ”„ Datenfluss

### 1. Scraping Phase
```
URLs â†’ Compliance Check â†’ Fetch â†’ Extract â†’ Validate â†’ Store in DB
```

### 2. Enrichment Phase
```
Records â†’ IPCC Enrichment â†’ Satellite Data â†’ Real-time Data â†’ Store in enriched_data
```

### 3. Geocoding Phase
```
Records â†’ Geocoding Service â†’ Update coordinates â†’ Store in records
```

### 4. Prediction Phase
```
Records + Enrichment â†’ Risk Scoring â†’ Predictions â†’ Store in regional_predictions
```

### 5. Frontend Display
```
Database â†’ API Endpoints â†’ Frontend â†’ User
```

## ğŸŒ Regionale Fokus-Regionen

### Deutschland
- **Keywords**: Germany, Deutschland, German
- **Country Codes**: DE
- **PrioritÃ¤t**: 1

### Europa
- **Keywords**: Europe, Europa, European, EU
- **Country Codes**: DE, FR, IT, ES, PL, NL, BE, AT, CH, CZ, SE, NO, DK, FI
- **PrioritÃ¤t**: 2

## ğŸ“Š Agent-Kommunikation

### Message Bus

Agenten kommunizieren Ã¼ber einen Message Bus:

```python
from master_orchestrator import AgentMessage, AgentMessageBus

message_bus = AgentMessageBus()

# Nachricht senden
message = AgentMessage(
    sender='scraper',
    receiver='enrichment',
    message_type='data',
    payload={'action': 'records_added', 'count': 10}
)
message_bus.publish(message)

# Nachrichten abonnieren
def handle_message(message):
    print(f"Received: {message.payload}")

message_bus.subscribe('enrichment', handle_message)
```

## ğŸ§ª Testing

### Integrationstest

```bash
python backend/test_integration.py
```

Testet:
- âœ… Datenbank-Verbindung
- âœ… Scraping-Komponenten
- âœ… Enrichment-Komponenten
- âœ… Geocoding
- âœ… Prediction-Komponenten
- âœ… Regionale Daten-Aggregation
- âœ… Frontend API

## ğŸš€ Verwendung

### 1. Komplette Pipeline ausfÃ¼hren

```bash
python backend/master_orchestrator.py
```

FÃ¼hrt aus:
1. Scraping von allen Datenquellen
2. Geocoding der Records
3. Enrichment mit IPCC-Daten
4. Erstellung von Predictions
5. Aggregation regionaler Daten

### 2. Frontend starten

```bash
python backend/web_app.py
```

Ã–ffne im Browser: `http://localhost:5000`

### 3. Einzelne Komponenten testen

```bash
# Scraping
python backend/run_pipeline.py

# Enrichment
python backend/run_ipcc_enrichment.py

# Predictions
python backend/run_enriched_predictions.py
```

## ğŸ”§ Konfiguration

### Environment Variables

```bash
# Firecrawl API
FIRECRAWL_API_KEY=fc-...

# OpenAI API (optional)
OPENAI_API_KEY=sk-...

# Rate Limiting
RATE_LIMIT=1.0
MAX_CONCURRENT=3

# Storage
STORAGE_DIR=./data
```

### Config (`config.py`)

Alle Konfigurationen werden zentral in `config.py` verwaltet.

## ğŸ“ˆ Monitoring

### Status abfragen

```python
status = orchestrator.get_status()
print(status)
```

Zeigt:
- Status aller Komponenten
- Datenbank-Statistiken
- Message Bus Status

### Logs

Strukturierte Logs mit `structlog`:
- Scraping-AktivitÃ¤ten
- Enrichment-Prozesse
- Fehler und Warnungen

## ğŸ› Troubleshooting

### Problem: Keine Records in Datenbank

**LÃ¶sung**: FÃ¼hre Scraping-Pipeline aus
```bash
python backend/run_pipeline.py
```

### Problem: Enrichment schlÃ¤gt fehl

**LÃ¶sung**: PrÃ¼fe Firecrawl API Key
```python
# In config.py oder .env
FIRECRAWL_API_KEY=fc-...
```

### Problem: Frontend zeigt keine Daten

**LÃ¶sung**: 
1. PrÃ¼fe ob Datenbank existiert: `./data/climate_conflict.db`
2. PrÃ¼fe API-Endpoints: `curl http://localhost:5000/api/stats`
3. PrÃ¼fe Browser-Konsole fÃ¼r Fehler

### Problem: Geocoding funktioniert nicht

**LÃ¶sung**: Geocoding-Service benÃ¶tigt Internet-Verbindung. PrÃ¼fe:
- Internet-Verbindung
- Geocoding-Service-API (falls verwendet)

## ğŸ“ Best Practices

1. **Immer Master Orchestrator verwenden** fÃ¼r vollstÃ¤ndige Pipeline
2. **Regionale Fokus-Regionen** definieren fÃ¼r bessere Performance
3. **Message Bus** nutzen fÃ¼r Agent-Kommunikation
4. **Datenbank-Indizes** verwenden fÃ¼r Performance
5. **Strukturierte Logs** fÃ¼r Debugging

## ğŸ”® Erweiterungen

### Neue Regionen hinzufÃ¼gen

In `master_orchestrator.py`:
```python
self.critical_regions['NewRegion'] = {
    'countries': ['XX'],
    'keywords': ['Keyword1', 'Keyword2'],
    'priority': 3
}
```

### Neue Datenquellen hinzufÃ¼gen

1. Erstelle Extractor in `extractors.py`
2. FÃ¼ge zu `ExtractorFactory` hinzu
3. FÃ¼ge URLs zu `url_lists.py` hinzu

### Neue Enrichment-Methoden

1. Erweitere `IPCCEnrichmentAgent`
2. FÃ¼ge zu `DynamicEnrichmentOrchestrator` hinzu
3. Update Datenbank-Schema falls nÃ¶tig

## ğŸ“š Weitere Dokumentation

- `README.md` - Allgemeine Ãœbersicht
- `PIPELINE_README.md` - Pipeline-Details
- `AGENT_README.md` - Agent-System
- `FRONTEND_SUMMARY.md` - Frontend-Details

